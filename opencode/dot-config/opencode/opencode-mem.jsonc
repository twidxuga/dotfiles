{
  // Storage configuration
  "storagePath": "~/.opencode-mem/data",
  
  // SQLite configuration for Apple Silicon Mac
  "customSqlitePath": "/opt/homebrew/opt/sqlite/lib/libsqlite3.dylib",
  
  // Embedding model for vector search (local, no API needed)
  "embeddingModel": "Xenova/nomic-embed-text-v1",
  
  // Web UI configuration
  "webServerEnabled": true,
  "webServerPort": 4747,
  
  // Memory capture settings
  "autoCaptureEnabled": true,
  
  // AI provider for memory analysis
  // Using Anthropic Claude 3.5 Haiku: 200K context (vs OpenAI's 128K)
  // Cheaper than gpt-4o-mini AND handles larger conversation batches
  "memoryProvider": "anthropic",
  "memoryModel": "claude-3-5-haiku-20241022",
  "memoryApiUrl": "https://api.anthropic.com/v1",
  "memoryApiKey": "env://ANTHROPIC_API_KEY",
  
  // User profile analysis interval (analyze every N prompts)
  // Can safely use 3 with Claude's 200K context (vs gpt-4o-mini's 128K)
  "userProfileAnalysisInterval": 3,
  
  // Maximum memories to retrieve in context
  "maxMemories": 10
}
